mobilenet.sm-fc4k.lr1e4.
MODEL NAME: mobilenet.sm-fc4k.lr1e4..h5
JSON FILE: my_drive/mobilenet.sm-fc4k.lr1e4.arch.json
WEIGHTS FILE: my_drive/mobilenet.sm-fc4k.lr1e4.weights.h5
EPOCHS: 60
layers to train:-3
DATE:2018-10-09 15:15
Image Size:224
BATCH SIZE:150
Number of classes:2
KERAS model:Mobilenet
TOP FCN:excluded
Input Shape:224x224x3
_________________________________________________________________

Layer (type)                 Output Shape              Param #   

=================================================================

input_3 (InputLayer)         (None, 224, 224, 3)       0         

_________________________________________________________________

conv1_pad (ZeroPadding2D)    (None, 226, 226, 3)       0         

_________________________________________________________________

conv1 (Conv2D)               (None, 112, 112, 32)      864       

_________________________________________________________________

conv1_bn (BatchNormalization (None, 112, 112, 32)      128       

_________________________________________________________________

conv1_relu (Activation)      (None, 112, 112, 32)      0         

_________________________________________________________________

conv_pad_1 (ZeroPadding2D)   (None, 114, 114, 32)      0         

_________________________________________________________________

conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       

_________________________________________________________________

conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       

_________________________________________________________________

conv_dw_1_relu (Activation)  (None, 112, 112, 32)      0         

_________________________________________________________________

conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      

_________________________________________________________________

conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       

_________________________________________________________________

conv_pw_1_relu (Activation)  (None, 112, 112, 64)      0         

_________________________________________________________________

conv_pad_2 (ZeroPadding2D)   (None, 114, 114, 64)      0         

_________________________________________________________________

conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       

_________________________________________________________________

conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       

_________________________________________________________________

conv_dw_2_relu (Activation)  (None, 56, 56, 64)        0         

_________________________________________________________________

conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      

_________________________________________________________________

conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_pw_2_relu (Activation)  (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pad_3 (ZeroPadding2D)   (None, 58, 58, 128)       0         

_________________________________________________________________

conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      

_________________________________________________________________

conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_dw_3_relu (Activation)  (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     

_________________________________________________________________

conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_pw_3_relu (Activation)  (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pad_4 (ZeroPadding2D)   (None, 58, 58, 128)       0         

_________________________________________________________________

conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      

_________________________________________________________________

conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       

_________________________________________________________________

conv_dw_4_relu (Activation)  (None, 28, 28, 128)       0         

_________________________________________________________________

conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     

_________________________________________________________________

conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_pw_4_relu (Activation)  (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pad_5 (ZeroPadding2D)   (None, 30, 30, 256)       0         

_________________________________________________________________

conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      

_________________________________________________________________

conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_dw_5_relu (Activation)  (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     

_________________________________________________________________

conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_pw_5_relu (Activation)  (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pad_6 (ZeroPadding2D)   (None, 30, 30, 256)       0         

_________________________________________________________________

conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      

_________________________________________________________________

conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      

_________________________________________________________________

conv_dw_6_relu (Activation)  (None, 14, 14, 256)       0         

_________________________________________________________________

conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    

_________________________________________________________________

conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_6_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_7 (ZeroPadding2D)   (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_7_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_7_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_8 (ZeroPadding2D)   (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_8_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_8_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_9 (ZeroPadding2D)   (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_9_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_9_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_10 (ZeroPadding2D)  (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_10_relu (Activation) (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_10_relu (Activation) (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_11 (ZeroPadding2D)  (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_11_relu (Activation) (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_11_relu (Activation) (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_12 (ZeroPadding2D)  (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      

_________________________________________________________________

conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      

_________________________________________________________________

conv_dw_12_relu (Activation) (None, 7, 7, 512)         0         

_________________________________________________________________

conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    

_________________________________________________________________

conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_pw_12_relu (Activation) (None, 7, 7, 1024)        0         

_________________________________________________________________

conv_pad_13 (ZeroPadding2D)  (None, 9, 9, 1024)        0         

_________________________________________________________________

conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      

_________________________________________________________________

conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_dw_13_relu (Activation) (None, 7, 7, 1024)        0         

_________________________________________________________________

conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   

_________________________________________________________________

conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_pw_13_relu (Activation) (None, 7, 7, 1024)        0         

_________________________________________________________________

global_max_pooling2d_1 (Glob (None, 1024)              0         

_________________________________________________________________

dense_5 (Dense)              (None, 1024)              1049600   

_________________________________________________________________

dense_6 (Dense)              (None, 2)                 2050      

=================================================================

Total params: 4,280,514

Trainable params: 1,051,650

Non-trainable params: 3,228,864

_________________________________________________________________

Data Aug Train:shear_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode='nearest',zoom_range=0.2
Data Aug Valid:
Compilationoptimizer='rmsprop',    loss='categorical_crossentropy', metrics=['accuracy']
Accuracy:0.3464335838005496
Accuracy:0.6515248196532992
Accuracy:0.6209008496255158
Accuracy:0.6691335997396515
Accuracy:0.7070307515098593
Accuracy:0.7388031136264025
Accuracy:0.7506698946023727
Accuracy:0.7652162764013704
Accuracy:0.7707030767154462
Accuracy:0.7685338784894788
Accuracy:0.7786142630541798
Accuracy:0.7849942580068904
Accuracy:0.7912466470358915
Accuracy:0.7977542418887211
Accuracy:0.796095444274767
Accuracy:0.7930330504062332
Accuracy:0.793415850509684
Accuracy:0.8075794310415827
Accuracy:0.8064310319100896
Accuracy:0.8161286231554846
Accuracy:0.8014546385282336
Accuracy:0.8154906192436744
Accuracy:0.8158734199783853
Accuracy:0.8096210266446465
Accuracy:0.8216154137344648
Accuracy:0.8121730211484762
Accuracy:0.8226362144489199
Accuracy:0.8282506058254732
Accuracy:0.8308026030292708
Accuracy:0.8291438019700055
Accuracy:0.8240398115172927
Accuracy:0.8213602115384806
Accuracy:0.8355237947703472
Accuracy:0.8374377986796736
Accuracy:0.8416485917557559
Accuracy:0.8462421846082506
Accuracy:0.8415209876041381
Accuracy:0.8352685995790686
Accuracy:0.831695805341899
Accuracy:0.8338650017197192
Accuracy:0.8468801827702699
Accuracy:0.8419037913430386
Accuracy:0.8480285789432066
Accuracy:0.8422865897504532
Accuracy:0.8457317835627214
Accuracy:0.8482837803482143
Accuracy:0.8453489872088036
Accuracy:0.8538981761055606
Accuracy:0.8468801847248947
Accuracy:0.8574709721376386
Accuracy:0.8477733797970454
Accuracy:0.8508357789514319
Accuracy:0.8514737746188329
Accuracy:0.8568329732074594
Accuracy:0.8582365777520816
Accuracy:0.8558121704242965
Accuracy:0.8547913708506729
Accuracy:0.850325382332329
Accuracy:0.8642337641591881
Accuracy:0.861554165412474
Validation Accuracy:0.8492753713027291
Validation Accuracy:0.15072464327449384
Validation Accuracy:0.26304348712058173
Validation Accuracy:0.6384058134711307
Validation Accuracy:0.9000000059604645
Validation Accuracy:0.9166666716337204
Validation Accuracy:0.9239130480133969
Validation Accuracy:0.9079710199781086
Validation Accuracy:0.905072469426238
Validation Accuracy:0.9057971070642057
Validation Accuracy:0.917391309271688
Validation Accuracy:0.9014492812363998
Validation Accuracy:0.917391309271688
Validation Accuracy:0.9007246435984321
Validation Accuracy:0.9028985565123351
Validation Accuracy:0.9231884103754292
Validation Accuracy:0.9188405845476233
Validation Accuracy:0.9166666716337204
Validation Accuracy:0.9021739188743674
Validation Accuracy:0.9137681210818498
Validation Accuracy:0.9246376856513645
Validation Accuracy:0.905072469426238
Validation Accuracy:0.9152173963577851
Validation Accuracy:0.9108695705299792
Validation Accuracy:0.9210144974615263
Validation Accuracy:0.9297101491171381
Validation Accuracy:0.9101449328920116
Validation Accuracy:0.9239130480133969
Validation Accuracy:0.9101449328920116
Validation Accuracy:0.931884062031041
Validation Accuracy:0.9333333373069763
Validation Accuracy:0.9304347867551057
Validation Accuracy:0.9282608738412028
Validation Accuracy:0.9217391350994939
Validation Accuracy:0.9289855114791704
Validation Accuracy:0.9304347867551057
Validation Accuracy:0.9086956576160763
Validation Accuracy:0.9036231941503027
Validation Accuracy:0.9210144974615263
Validation Accuracy:0.9137681210818498
Validation Accuracy:0.9108695705299792
Validation Accuracy:0.9202898598235586
Validation Accuracy:0.9108695705299792
Validation Accuracy:0.9123188458059145
Validation Accuracy:0.9181159469096557
Validation Accuracy:0.9297101491171381
Validation Accuracy:0.9239130480133969
Validation Accuracy:0.9311594243930734
Validation Accuracy:0.931884062031041
Validation Accuracy:0.9311594243930734
Validation Accuracy:0.9188405845476233
Validation Accuracy:0.9166666716337204
Validation Accuracy:0.931884062031041
Validation Accuracy:0.9297101491171381
Validation Accuracy:0.9282608738412028
Validation Accuracy:0.9347826125829116
Validation Accuracy:0.9101449328920116
Validation Accuracy:0.9304347867551057
Validation Accuracy:0.931884062031041
Validation Accuracy:0.9347826125829116
Loss:10.446473973250988
Loss:5.488489018907896
Loss:4.164829786857871
Loss:1.37143297567802
Loss:1.0741426020507014
Loss:0.8875898074644385
Loss:0.8053860216857494
Loss:0.7281999415595023
Loss:0.7029253013990082
Loss:0.6694266868060502
Loss:0.6243879652774743
Loss:0.5954684682216087
Loss:0.5851212106098459
Loss:0.5508085051155736
Loss:0.542370015197952
Loss:0.5512291726613358
Loss:0.5164982817626903
Loss:0.48940188872071877
Loss:0.4986028283229817
Loss:0.46762825776244726
Loss:0.49964727788566554
Loss:0.45704255481908346
Loss:0.45930149790369706
Loss:0.4707543211535743
Loss:0.4429795107922719
Loss:0.4616618677412838
Loss:0.43338653164979557
Loss:0.43108416787820825
Loss:0.4134948617100518
Loss:0.41937025675317896
Loss:0.4133783071620954
Loss:0.42251668967990164
Loss:0.3956191482266495
Loss:0.3932219761981942
Loss:0.38394576387547164
Loss:0.37195864150958263
Loss:0.38644768774729993
Loss:0.38496146277325244
Loss:0.39525684163295693
Loss:0.38236035329203105
Loss:0.36263880282317223
Loss:0.35817940361846295
Loss:0.355983096647509
Loss:0.36927201222883616
Loss:0.35771933416824675
Loss:0.3578348526548363
Loss:0.3624601133003274
Loss:0.341972053948449
Loss:0.3557620699937754
Loss:0.336215995104775
Loss:0.3468547435580764
Loss:0.348063253331157
Loss:0.33574444272125104
Loss:0.33194789701507793
Loss:0.3301726239203981
Loss:0.33329500346383345
Loss:0.32688959293695863
Loss:0.3382924108598341
Loss:0.31332437051784573
Loss:0.32781741519325375
Validation Loss:2.086735994248596
Validation Loss:13.349817099778548
Validation Loss:2.644244387097981
Validation Loss:0.9428409289406694
Validation Loss:0.33279521526444866
Validation Loss:0.2576338518107229
Validation Loss:0.23880924755687136
Validation Loss:0.2786880247598595
Validation Loss:0.33519106315962627
Validation Loss:0.3471700708665278
Validation Loss:0.25221930501815537
Validation Loss:0.4099154374941819
Validation Loss:0.2496254258610703
Validation Loss:0.43427974514159595
Validation Loss:0.4226683287150714
Validation Loss:0.22124201245479408
Validation Loss:0.3086872108613771
Validation Loss:0.28470138737833145
Validation Loss:0.433825810427389
Validation Loss:0.3165457961488004
Validation Loss:0.23198565126918053
Validation Loss:0.4261574559563008
Validation Loss:0.3104713183024812
Validation Loss:0.3375037680576181
Validation Loss:0.2864162195733313
Validation Loss:0.21285851967379288
Validation Loss:0.3563400327799647
Validation Loss:0.2603509892265404
Validation Loss:0.33748661756164994
Validation Loss:0.2093482591634434
Validation Loss:0.20995797275606057
Validation Loss:0.2331897628091215
Validation Loss:0.2403330047217542
Validation Loss:0.28921643395322305
Validation Loss:0.2429907696148249
Validation Loss:0.2055660458231021
Validation Loss:0.39404864051365346
Validation Loss:0.4823997274806575
Validation Loss:0.3070465369939642
Validation Loss:0.326676512910205
Validation Loss:0.37039167603902373
Validation Loss:0.30899284182068304
Validation Loss:0.36397220729391533
Validation Loss:0.3451959679370465
Validation Loss:0.31364629150116147
Validation Loss:0.19679260716277538
Validation Loss:0.27862504310779396
Validation Loss:0.20967445820671224
Validation Loss:0.25035494168664824
Validation Loss:0.24606923639151754
Validation Loss:0.34795216823144787
Validation Loss:0.3375375793652695
Validation Loss:0.2596822800658866
Validation Loss:0.25052996038942615
Validation Loss:0.2572065787280735
Validation Loss:0.19724060230098828
Validation Loss:0.4326209908372814
Validation Loss:0.2402994908688529
Validation Loss:0.20154808540372987
Validation Loss:0.21634129937814103
Confusion MatrixTN:1149 FP:23 FN:67 TP:141
             precision    recall  f1-score   support

  No Litter       0.94      0.98      0.96      1172
     Litter       0.86      0.68      0.76       208

avg / total       0.93      0.93      0.93      1380

DATE:2018-10-09 17:54
