mobilenet.sm-fc1k.fc1k.1r1e4.1.
MODEL NAME: mobilenet.sm-fc1k.fc1k.1r1e4.1..h5
JSON FILE: ./mobilenet.sm-fc1k.fc1k.1r1e4.1.arch.json
WEIGHTS FILE: ./mobilenet.sm-fc1k.fc1k.1r1e4.1.weights.h5
EPOCHS: 37
layers to train:-20
DATE:2018-10-10 22:33
Image Size:224
BATCH SIZE:150
Number of classes:2
KERAS model:Mobilenet
TOP FCN:excluded
Input Shape:224x224x3
_________________________________________________________________

Layer (type)                 Output Shape              Param #   

=================================================================

input_1 (InputLayer)         (None, 224, 224, 3)       0         

_________________________________________________________________

conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         

_________________________________________________________________

conv1 (Conv2D)               (None, 112, 112, 32)      864       

_________________________________________________________________

conv1_bn (BatchNormalization (None, 112, 112, 32)      128       

_________________________________________________________________

conv1_relu (ReLU)            (None, 112, 112, 32)      0         

_________________________________________________________________

conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       

_________________________________________________________________

conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       

_________________________________________________________________

conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         

_________________________________________________________________

conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      

_________________________________________________________________

conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       

_________________________________________________________________

conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         

_________________________________________________________________

conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         

_________________________________________________________________

conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       

_________________________________________________________________

conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       

_________________________________________________________________

conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         

_________________________________________________________________

conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      

_________________________________________________________________

conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         

_________________________________________________________________

conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      

_________________________________________________________________

conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     

_________________________________________________________________

conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         

_________________________________________________________________

conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      

_________________________________________________________________

conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       

_________________________________________________________________

conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         

_________________________________________________________________

conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     

_________________________________________________________________

conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         

_________________________________________________________________

conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      

_________________________________________________________________

conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     

_________________________________________________________________

conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         

_________________________________________________________________

conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      

_________________________________________________________________

conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      

_________________________________________________________________

conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         

_________________________________________________________________

conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    

_________________________________________________________________

conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         

_________________________________________________________________

conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      

_________________________________________________________________

conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      

_________________________________________________________________

conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         

_________________________________________________________________

conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    

_________________________________________________________________

conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         

_________________________________________________________________

conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      

_________________________________________________________________

conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         

_________________________________________________________________

conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   

_________________________________________________________________

conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         

_________________________________________________________________

flatten_1 (Flatten)          (None, 50176)             0         

_________________________________________________________________

dense_1 (Dense)              (None, 2)                 100354    

=================================================================

Total params: 3,329,218

Trainable params: 1,958,402

Non-trainable params: 1,370,816

_________________________________________________________________

Data Aug Train:shear_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode='nearest',zoom_range=0.2
Data Aug Valid:
Compilationoptimizer='rmsprop',    loss='categorical_crossentropy', metrics=['accuracy']
Accuracy:0.7400407858400585
Accuracy:0.8337185568018562
Accuracy:0.8693405837934898
Accuracy:0.8832087022037752
Accuracy:0.902107410776137
Accuracy:0.9118966690785701
Accuracy:0.9250849783623162
Accuracy:0.9318830684121169
Accuracy:0.9332426934725244
Accuracy:0.9389530880203221
Accuracy:0.9447994504470877
Accuracy:0.946159072103831
Accuracy:0.9490142747871249
Accuracy:0.9556764054671183
Accuracy:0.9602991127789547
Accuracy:0.9608429587673444
Accuracy:0.9619306565789768
Accuracy:0.9656016327425544
Accuracy:0.9702243399328313
Accuracy:0.9715839568487565
Accuracy:0.9740312740075029
Accuracy:0.9721278087935588
Accuracy:0.9707681883524097
Accuracy:0.977430326447529
Accuracy:0.9723997313015158
Accuracy:0.9800136018820477
Accuracy:0.9766145544259586
Accuracy:0.9806934108870278
Accuracy:0.9817811089417791
Accuracy:0.9809653367986491
Accuracy:0.9812372580910118
Accuracy:0.9830047722011905
Accuracy:0.9846363116250728
Accuracy:0.9839564989733096
Accuracy:0.9857240046958872
Accuracy:0.9872195870595916
Accuracy:0.985724006033041
Validation Accuracy:0.9217391350994939
Validation Accuracy:0.9275362362032351
Validation Accuracy:0.9413043513246204
Validation Accuracy:0.9427536266005557
Validation Accuracy:0.9507246406181998
Validation Accuracy:0.9471014524283616
Validation Accuracy:0.956521741721941
Validation Accuracy:0.9536231911700704
Validation Accuracy:0.9594202922738116
Validation Accuracy:0.9579710169978763
Validation Accuracy:0.9557971040839734
Validation Accuracy:0.9601449299117794
Validation Accuracy:0.9528985535321028
Validation Accuracy:0.9615942051877147
Validation Accuracy:0.9637681181016176
Validation Accuracy:0.96304348046365
Validation Accuracy:0.9514492782561675
Validation Accuracy:0.9507246406181998
Validation Accuracy:0.9514492782561675
Validation Accuracy:0.960869567549747
Validation Accuracy:0.9572463793599088
Validation Accuracy:0.958695654635844
Validation Accuracy:0.9536231911700704
Validation Accuracy:0.944202901876491
Validation Accuracy:0.9644927557395853
Validation Accuracy:0.9652173933775529
Validation Accuracy:0.9644927557395853
Validation Accuracy:0.9528985535321028
Validation Accuracy:0.96304348046365
Validation Accuracy:0.9666666686534882
Validation Accuracy:0.9623188428256823
Validation Accuracy:0.9543478288080381
Validation Accuracy:0.9673913062914558
Validation Accuracy:0.9507246406181998
Validation Accuracy:0.9347826125829116
Validation Accuracy:0.9500000029802322
Validation Accuracy:0.9601449299117794
Loss:1.116621673998583
Loss:0.5811704714876871
Loss:0.4447462489862656
Loss:0.40648462653241135
Loss:0.32657878004637486
Loss:0.3205823874586014
Loss:0.24806577691024537
Loss:0.2401024435695424
Loss:0.23935011761639088
Loss:0.186468090697424
Loss:0.17918408095543345
Loss:0.1906467051549804
Loss:0.17121201626263827
Loss:0.14450641143066717
Loss:0.1403293107889309
Loss:0.12906333377356163
Loss:0.12035138022222946
Loss:0.10976018000996839
Loss:0.09231459554272149
Loss:0.08683766015975614
Loss:0.07961037914559276
Loss:0.08153469302519943
Loss:0.08982608970799144
Loss:0.07406310297231894
Loss:0.08306133210233094
Loss:0.06510079402114403
Loss:0.06684618316994738
Loss:0.058284918040848815
Loss:0.06446523755867323
Loss:0.062048224081746844
Loss:0.05761593830749624
Loss:0.05169461351736397
Loss:0.04659526017485003
Loss:0.049797816583302686
Loss:0.03937335341490101
Loss:0.038955555129340416
Loss:0.04979919507953008
Validation Loss:0.2810575451079311
Validation Loss:0.3246052144607782
Validation Loss:0.22945357928477714
Validation Loss:0.2876628555100267
Validation Loss:0.2369202415916927
Validation Loss:0.27189297813137
Validation Loss:0.2297328257262289
Validation Loss:0.2555081538600422
Validation Loss:0.23097402726251975
Validation Loss:0.24133025137116024
Validation Loss:0.2426541664347536
Validation Loss:0.21493340710319742
Validation Loss:0.2725226027869212
Validation Loss:0.22817013675644968
Validation Loss:0.1992386717948134
Validation Loss:0.20384254483234027
Validation Loss:0.29214634554338537
Validation Loss:0.290567027981524
Validation Loss:0.26081742907310557
Validation Loss:0.2310616525428486
Validation Loss:0.2434504435540594
Validation Loss:0.24719397482271155
Validation Loss:0.3084901237185408
Validation Loss:0.37000643171762454
Validation Loss:0.21760067267120536
Validation Loss:0.21133242601978924
Validation Loss:0.23591685028559764
Validation Loss:0.2844856093880757
Validation Loss:0.22461806953995858
Validation Loss:0.2276261382312441
Validation Loss:0.23915685613507737
Validation Loss:0.2710891417398512
Validation Loss:0.22160816273289247
Validation Loss:0.3140961138894952
Validation Loss:0.5029822280255967
Validation Loss:0.281645685124006
Validation Loss:0.25623156519103085
Confusion MatrixTN:1134 FP:38 FN:17 TP:191
             precision    recall  f1-score   support

  No Litter       0.99      0.97      0.98      1172
     Litter       0.83      0.92      0.87       208

avg / total       0.96      0.96      0.96      1380

DATE:2018-10-10 23:19
