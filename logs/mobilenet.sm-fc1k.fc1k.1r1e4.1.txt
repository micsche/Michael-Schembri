mobilenet.sm-fc4k.fc1k.lr1e4.
MODEL NAME: mobilenet.sm-fc4k.fc1k.lr1e4..h5
JSON FILE: ./mobilenet.sm-fc4k.fc1k.lr1e4.arch.json
WEIGHTS FILE: ./mobilenet.sm-fc4k.fc1k.lr1e4.weights.h5
EPOCHS: 60
layers to train:-13
DATE:2018-10-10 21:09
Image Size:224
BATCH SIZE:150
Number of classes:2
KERAS model:Mobilenet
TOP FCN:excluded
Input Shape:224x224x3
_________________________________________________________________

Layer (type)                 Output Shape              Param #   

=================================================================

input_1 (InputLayer)         (None, 224, 224, 3)       0         

_________________________________________________________________

conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         

_________________________________________________________________

conv1 (Conv2D)               (None, 112, 112, 32)      864       

_________________________________________________________________

conv1_bn (BatchNormalization (None, 112, 112, 32)      128       

_________________________________________________________________

conv1_relu (ReLU)            (None, 112, 112, 32)      0         

_________________________________________________________________

conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       

_________________________________________________________________

conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       

_________________________________________________________________

conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         

_________________________________________________________________

conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      

_________________________________________________________________

conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       

_________________________________________________________________

conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         

_________________________________________________________________

conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         

_________________________________________________________________

conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       

_________________________________________________________________

conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       

_________________________________________________________________

conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         

_________________________________________________________________

conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      

_________________________________________________________________

conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         

_________________________________________________________________

conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      

_________________________________________________________________

conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     

_________________________________________________________________

conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         

_________________________________________________________________

conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      

_________________________________________________________________

conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       

_________________________________________________________________

conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         

_________________________________________________________________

conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     

_________________________________________________________________

conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         

_________________________________________________________________

conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      

_________________________________________________________________

conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     

_________________________________________________________________

conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         

_________________________________________________________________

conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      

_________________________________________________________________

conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      

_________________________________________________________________

conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         

_________________________________________________________________

conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    

_________________________________________________________________

conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         

_________________________________________________________________

conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         

_________________________________________________________________

conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      

_________________________________________________________________

conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      

_________________________________________________________________

conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         

_________________________________________________________________

conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    

_________________________________________________________________

conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         

_________________________________________________________________

conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      

_________________________________________________________________

conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         

_________________________________________________________________

conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   

_________________________________________________________________

conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         

_________________________________________________________________

flatten_1 (Flatten)          (None, 50176)             0         

_________________________________________________________________

dense_1 (Dense)              (None, 2)                 100354    

=================================================================

Total params: 3,329,218

Trainable params: 1,689,602

Non-trainable params: 1,639,616

_________________________________________________________________

Data Aug Train:shear_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode='nearest',zoom_range=0.2
Data Aug Valid:
Compilationoptimizer='rmsprop',    loss='categorical_crossentropy', metrics=['accuracy']
Accuracy:0.7517335148266105
Accuracy:0.8285520083640077
Accuracy:0.845955134815784
Accuracy:0.8754588710378417
Accuracy:0.8934058544183572
Accuracy:0.8875594872507735
Accuracy:0.9113528243057749
Accuracy:0.9074099284301074
Accuracy:0.9104010856208309
Accuracy:0.9195105395375426
Accuracy:0.9208701563319084
Accuracy:0.9317471078267152
Accuracy:0.9341944213386785
Accuracy:0.9399048267052661
Accuracy:0.9388171299876688
Accuracy:0.9449354122480838
Accuracy:0.9447994514195632
Accuracy:0.948742350942014
Accuracy:0.95608429439533
Accuracy:0.9520054356246316
Accuracy:0.9556764015772162
Accuracy:0.9535010166511821
Accuracy:0.9583956439182274
Accuracy:0.9624745025673664
Accuracy:0.9596193072991984
Accuracy:0.959483344282608
Accuracy:0.9636981613290788
Accuracy:0.9642420098702167
Accuracy:0.9692726074474187
Accuracy:0.9692726013694467
Accuracy:0.966553370211904
Accuracy:0.974711083012483
Accuracy:0.9745751223055219
Accuracy:0.9738953147592551
Accuracy:0.974167235808499
Accuracy:0.9718558840975318
Accuracy:0.9733514650025228
Accuracy:0.9755268600179904
Accuracy:0.977158402845537
Accuracy:0.977838212944552
Accuracy:0.9801495672082674
Accuracy:0.9806934121026222
Accuracy:0.9805574515172205
Accuracy:0.9819170695271806
Accuracy:0.9819170743895582
Accuracy:0.9825968797477551
Accuracy:0.9809653416610267
Accuracy:0.9834126554161088
Accuracy:0.981917070742775
Accuracy:0.9835486156165721
Accuracy:0.9854520834035244
Accuracy:0.9851801551822738
Accuracy:0.9834126492165773
Accuracy:0.9821889979915502
Accuracy:0.9865397768390171
Accuracy:0.9790618680594811
Accuracy:0.983820538387908
Accuracy:0.9849082363210998
Accuracy:0.9877634377887993
Accuracy:0.9891230522735357
Validation Accuracy:0.9224637727374616
Validation Accuracy:0.8971014554085939
Validation Accuracy:0.9456521771524263
Validation Accuracy:0.9507246406181998
Validation Accuracy:0.9427536266005557
Validation Accuracy:0.9507246406181998
Validation Accuracy:0.9521739158941351
Validation Accuracy:0.9528985535321028
Validation Accuracy:0.9500000029802322
Validation Accuracy:0.9507246406181998
Validation Accuracy:0.9521739158941351
Validation Accuracy:0.956521741721941
Validation Accuracy:0.9543478288080381
Validation Accuracy:0.9572463793599088
Validation Accuracy:0.9572463793599088
Validation Accuracy:0.9514492782561675
Validation Accuracy:0.9507246406181998
Validation Accuracy:0.9550724664460057
Validation Accuracy:0.9594202922738116
Validation Accuracy:0.958695654635844
Validation Accuracy:0.9637681181016176
Validation Accuracy:0.958695654635844
Validation Accuracy:0.9615942051877147
Validation Accuracy:0.956521741721941
Validation Accuracy:0.9601449299117794
Validation Accuracy:0.9536231911700704
Validation Accuracy:0.9514492782561675
Validation Accuracy:0.9543478288080381
Validation Accuracy:0.9543478288080381
Validation Accuracy:0.958695654635844
Validation Accuracy:0.9521739158941351
Validation Accuracy:0.9514492782561675
Validation Accuracy:0.9572463793599088
Validation Accuracy:0.9557971040839734
Validation Accuracy:0.9579710169978763
Validation Accuracy:0.9384058007727498
Validation Accuracy:0.9659420310155206
Validation Accuracy:0.9159420339957528
Validation Accuracy:0.9615942051877147
Validation Accuracy:0.9427536266005557
Validation Accuracy:0.9485507277042969
Validation Accuracy:0.9594202922738116
Validation Accuracy:0.9601449299117794
Validation Accuracy:0.9594202922738116
Validation Accuracy:0.9427536266005557
Validation Accuracy:0.9644927557395853
Validation Accuracy:0.9478260900663293
Validation Accuracy:0.9644927557395853
Validation Accuracy:0.9594202922738116
Validation Accuracy:0.956521741721941
Validation Accuracy:0.9543478288080381
Validation Accuracy:0.9623188428256823
Validation Accuracy:0.9637681181016176
Validation Accuracy:0.960869567549747
Validation Accuracy:0.9514492782561675
Validation Accuracy:0.9644927557395853
Validation Accuracy:0.958695654635844
Validation Accuracy:0.9637681181016176
Validation Accuracy:0.9601449299117794
Validation Accuracy:0.9333333373069763
Loss:1.0391597659266942
Loss:0.6141314210330929
Loss:0.566401115534441
Loss:0.4295720914688992
Loss:0.37483552456114827
Loss:0.40022361935588024
Loss:0.2932066477469234
Loss:0.34455692635901036
Loss:0.29877407359051755
Loss:0.2772191809623279
Loss:0.25768030979331863
Loss:0.22267955329087466
Loss:0.2269651186934221
Loss:0.1958400525866845
Loss:0.19149880760420876
Loss:0.17739470494894613
Loss:0.17636759691117654
Loss:0.1696403997384878
Loss:0.15125515897467703
Loss:0.1533301990291431
Loss:0.14712335747735666
Loss:0.15611684690303987
Loss:0.13347748314445224
Loss:0.12542838812188417
Loss:0.12926065633586278
Loss:0.12037135472737713
Loss:0.11317273797524333
Loss:0.11222168024221624
Loss:0.1021952082117931
Loss:0.08598909487431783
Loss:0.10949418140788335
Loss:0.08056934374396611
Loss:0.08524127500821829
Loss:0.08205029196173562
Loss:0.08241879600489589
Loss:0.07890573150796763
Loss:0.08781715597622451
Loss:0.0722785235935332
Loss:0.08006020800927863
Loss:0.07221081520143939
Loss:0.06277339809265857
Loss:0.05812901393670611
Loss:0.06409605135185166
Loss:0.05806798885249103
Loss:0.05470228331659893
Loss:0.05713591427161763
Loss:0.061507447547058336
Loss:0.06142833234234521
Loss:0.05829566676969307
Loss:0.05210438306221167
Loss:0.05510579245047863
Loss:0.04586021939101347
Loss:0.04227139431613489
Loss:0.05868143745939628
Loss:0.04408146437623314
Loss:0.06031637036344157
Loss:0.047255403349235565
Loss:0.04613944738539839
Loss:0.0413777290409422
Loss:0.030833665833300085
Validation Loss:0.2571827917076323
Validation Loss:0.3287214351736981
Validation Loss:0.21156516697247635
Validation Loss:0.20778471974494017
Validation Loss:0.273732182340451
Validation Loss:0.22954724437010515
Validation Loss:0.21780884147206644
Validation Loss:0.20938351902219912
Validation Loss:0.24259393452983047
Validation Loss:0.22687933643338393
Validation Loss:0.22678505380653127
Validation Loss:0.22250454155120836
Validation Loss:0.23225651620115337
Validation Loss:0.21742754532770842
Validation Loss:0.20486932190618498
Validation Loss:0.2739260670423589
Validation Loss:0.24643137293827275
Validation Loss:0.23582229693008983
Validation Loss:0.21156972341755728
Validation Loss:0.22842917591459927
Validation Loss:0.2030384360069824
Validation Loss:0.2380786271033171
Validation Loss:0.216092940469895
Validation Loss:0.2726458446036304
Validation Loss:0.22423624085904917
Validation Loss:0.33263867464058977
Validation Loss:0.3034569291798423
Validation Loss:0.26687164207325387
Validation Loss:0.3079010461457548
Validation Loss:0.25240443917597155
Validation Loss:0.27756952331338136
Validation Loss:0.27589648851888976
Validation Loss:0.2383723635272042
Validation Loss:0.23317046006685932
Validation Loss:0.26311572287067975
Validation Loss:0.46168028681327655
Validation Loss:0.2106538684210255
Validation Loss:0.3390882392262068
Validation Loss:0.23784499992705052
Validation Loss:0.2644617898983162
Validation Loss:0.35531755566175544
Validation Loss:0.23785203195597127
Validation Loss:0.28184795595914536
Validation Loss:0.2535539606098372
Validation Loss:0.28235197409673635
Validation Loss:0.21244509055585417
Validation Loss:0.3498156152880963
Validation Loss:0.24468372221117138
Validation Loss:0.26621703984077927
Validation Loss:0.38990796277503614
Validation Loss:0.3599598013954114
Validation Loss:0.2615894639488844
Validation Loss:0.2512027760972555
Validation Loss:0.26015618287055986
Validation Loss:0.2845011415787588
Validation Loss:0.2472411646181765
Validation Loss:0.2823284262539403
Validation Loss:0.23776017463229515
Validation Loss:0.26781311157537857
Validation Loss:0.5586152002319433
Confusion MatrixTN:1167 FP:5 FN:87 TP:121
             precision    recall  f1-score   support

  No Litter       0.93      1.00      0.96      1172
     Litter       0.96      0.58      0.72       208

avg / total       0.94      0.93      0.93      1380

DATE:2018-10-10 22:23
