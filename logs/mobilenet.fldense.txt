mobilenet.sm.lr1e4.
MODEL NAME: mobilenet.sm.lr1e4..h5
JSON FILE: my_drive/mobilenet.sm.lr1e4.arch.json
WEIGHTS FILE: my_drive/mobilenet.sm.lr1e4.weights.h5
EPOCHS: 60
layers to train:-2
DATE:2018-10-09 09:12
Image Size:224
BATCH SIZE:150
Number of classes:2
BATCH SIZE:150
Number of classes:2
KERAS model:Mobilenet
TOP FCN:excluded
Input Shape:224x224x3
_________________________________________________________________

Layer (type)                 Output Shape              Param #   

=================================================================

input_1 (InputLayer)         (None, 224, 224, 3)       0         

_________________________________________________________________

conv1_pad (ZeroPadding2D)    (None, 226, 226, 3)       0         

_________________________________________________________________

conv1 (Conv2D)               (None, 112, 112, 32)      864       

_________________________________________________________________

conv1_bn (BatchNormalization (None, 112, 112, 32)      128       

_________________________________________________________________

conv1_relu (Activation)      (None, 112, 112, 32)      0         

_________________________________________________________________

conv_pad_1 (ZeroPadding2D)   (None, 114, 114, 32)      0         

_________________________________________________________________

conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       

_________________________________________________________________

conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       

_________________________________________________________________

conv_dw_1_relu (Activation)  (None, 112, 112, 32)      0         

_________________________________________________________________

conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      

_________________________________________________________________

conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       

_________________________________________________________________

conv_pw_1_relu (Activation)  (None, 112, 112, 64)      0         

_________________________________________________________________

conv_pad_2 (ZeroPadding2D)   (None, 114, 114, 64)      0         

_________________________________________________________________

conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       

_________________________________________________________________

conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       

_________________________________________________________________

conv_dw_2_relu (Activation)  (None, 56, 56, 64)        0         

_________________________________________________________________

conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      

_________________________________________________________________

conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_pw_2_relu (Activation)  (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pad_3 (ZeroPadding2D)   (None, 58, 58, 128)       0         

_________________________________________________________________

conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      

_________________________________________________________________

conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_dw_3_relu (Activation)  (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     

_________________________________________________________________

conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       

_________________________________________________________________

conv_pw_3_relu (Activation)  (None, 56, 56, 128)       0         

_________________________________________________________________

conv_pad_4 (ZeroPadding2D)   (None, 58, 58, 128)       0         

_________________________________________________________________

conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      

_________________________________________________________________

conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       

_________________________________________________________________

conv_dw_4_relu (Activation)  (None, 28, 28, 128)       0         

_________________________________________________________________

conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     

_________________________________________________________________

conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_pw_4_relu (Activation)  (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pad_5 (ZeroPadding2D)   (None, 30, 30, 256)       0         

_________________________________________________________________

conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      

_________________________________________________________________

conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_dw_5_relu (Activation)  (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     

_________________________________________________________________

conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      

_________________________________________________________________

conv_pw_5_relu (Activation)  (None, 28, 28, 256)       0         

_________________________________________________________________

conv_pad_6 (ZeroPadding2D)   (None, 30, 30, 256)       0         

_________________________________________________________________

conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      

_________________________________________________________________

conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      

_________________________________________________________________

conv_dw_6_relu (Activation)  (None, 14, 14, 256)       0         

_________________________________________________________________

conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    

_________________________________________________________________

conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_6_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_7 (ZeroPadding2D)   (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_7_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_7_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_8 (ZeroPadding2D)   (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_8_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_8_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_9 (ZeroPadding2D)   (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_9_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_9_relu (Activation)  (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_10 (ZeroPadding2D)  (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_10_relu (Activation) (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_10_relu (Activation) (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_11 (ZeroPadding2D)  (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      

_________________________________________________________________

conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_dw_11_relu (Activation) (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    

_________________________________________________________________

conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      

_________________________________________________________________

conv_pw_11_relu (Activation) (None, 14, 14, 512)       0         

_________________________________________________________________

conv_pad_12 (ZeroPadding2D)  (None, 16, 16, 512)       0         

_________________________________________________________________

conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      

_________________________________________________________________

conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      

_________________________________________________________________

conv_dw_12_relu (Activation) (None, 7, 7, 512)         0         

_________________________________________________________________

conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    

_________________________________________________________________

conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_pw_12_relu (Activation) (None, 7, 7, 1024)        0         

_________________________________________________________________

conv_pad_13 (ZeroPadding2D)  (None, 9, 9, 1024)        0         

_________________________________________________________________

conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      

_________________________________________________________________

conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_dw_13_relu (Activation) (None, 7, 7, 1024)        0         

_________________________________________________________________

conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   

_________________________________________________________________

conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

_________________________________________________________________

conv_pw_13_relu (Activation) (None, 7, 7, 1024)        0         

_________________________________________________________________

flatten_1 (Flatten)          (None, 50176)             0         

_________________________________________________________________

dense_1 (Dense)              (None, 2)                 100354    

=================================================================

Total params: 3,329,218

Trainable params: 100,354

Non-trainable params: 3,228,864

_________________________________________________________________

Data Aug Train:shear_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode='nearest',zoom_range=0.2
Data Aug Valid:
Compilationoptimizer='rmsprop',    loss='categorical_crossentropy', metrics=['accuracy']
Accuracy:0.7069031470083865
Accuracy:0.7897154545926981
Accuracy:0.8023478346955827
Accuracy:0.8244226110655388
Accuracy:0.8272298084422461
Accuracy:0.839351792138983
Accuracy:0.8541533789784381
Accuracy:0.841010589121677
Accuracy:0.8521117773441783
Accuracy:0.8554293774624511
Accuracy:0.8649993609968338
Accuracy:0.8627025613344277
Accuracy:0.8724001518116627
Accuracy:0.8607885647340288
Accuracy:0.8676789601618529
Accuracy:0.8647441653416171
Accuracy:0.8815873468106264
Accuracy:0.8734209542677873
Accuracy:0.8789077447326843
Accuracy:0.8729105581126226
Accuracy:0.8891157379058515
Accuracy:0.8791629479782335
Accuracy:0.8840117405853329
Accuracy:0.8810769439017391
Accuracy:0.8869465368734386
Accuracy:0.8869465381055367
Accuracy:0.8880949367274583
Accuracy:0.8884777348534678
Accuracy:0.8812045401131695
Accuracy:0.8935817261427903
Accuracy:0.8836289440184599
Accuracy:0.8869465381055367
Accuracy:0.8845221451446234
Accuracy:0.8951129251267512
Accuracy:0.8782697487154283
Accuracy:0.8976649252434721
Accuracy:0.8883501383454212
Accuracy:0.8988133273791549
Accuracy:0.8877121409743784
Accuracy:0.8907745317246395
Accuracy:0.8971545263427062
Accuracy:0.9017481202903992
Accuracy:0.8948577294259012
Accuracy:0.8940921318885454
Accuracy:0.8894985394087224
Accuracy:0.8951129261306829
Accuracy:0.8865637377891307
Accuracy:0.8997065219417342
Accuracy:0.8859257398856999
Accuracy:0.9008549149507646
Accuracy:0.8988133250518585
Accuracy:0.9026413180397013
Accuracy:0.8979201216896654
Accuracy:0.9040449160207393
Accuracy:0.898685728026635
Accuracy:0.9048105144631547
Accuracy:0.9067245170947498
Accuracy:0.9068521175881011
Accuracy:0.9039173186684775
Accuracy:0.8968993287100481
Validation Accuracy:0.9086956576160763
Validation Accuracy:0.9152173963577851
Validation Accuracy:0.9268115985652675
Validation Accuracy:0.9188405845476233
Validation Accuracy:0.9347826125829116
Validation Accuracy:0.919565222185591
Validation Accuracy:0.9239130480133969
Validation Accuracy:0.9326086996690087
Validation Accuracy:0.9326086996690087
Validation Accuracy:0.9297101491171381
Validation Accuracy:0.9369565254968145
Validation Accuracy:0.9405797136866528
Validation Accuracy:0.9224637727374616
Validation Accuracy:0.9391304384107175
Validation Accuracy:0.9376811631347822
Validation Accuracy:0.9384058007727498
Validation Accuracy:0.9152173963577851
Validation Accuracy:0.9391304384107175
Validation Accuracy:0.9420289889625881
Validation Accuracy:0.9231884103754292
Validation Accuracy:0.8253623292497967
Validation Accuracy:0.9355072502208792
Validation Accuracy:0.9384058007727498
Validation Accuracy:0.9427536266005557
Validation Accuracy:0.8920289919428204
Validation Accuracy:0.8507246462547261
Validation Accuracy:0.9355072502208792
Validation Accuracy:0.8731884133556614
Validation Accuracy:0.8318840679915055
Validation Accuracy:0.9413043513246204
Validation Accuracy:0.9043478317882704
Validation Accuracy:0.9434782642385234
Validation Accuracy:0.9413043513246204
Validation Accuracy:0.9398550760486851
Validation Accuracy:0.9405797136866528
Validation Accuracy:0.9413043513246204
Validation Accuracy:0.9405797136866528
Validation Accuracy:0.9434782642385234
Validation Accuracy:0.9347826125829116
Validation Accuracy:0.8195652281460555
Validation Accuracy:0.7833333459237347
Validation Accuracy:0.8065217506626378
Validation Accuracy:0.7659420429364495
Validation Accuracy:0.9340579749449439
Validation Accuracy:0.7507246518912523
Validation Accuracy:0.9376811631347822
Validation Accuracy:0.9000000059604645
Validation Accuracy:0.8079710256146349
Validation Accuracy:0.9275362362032351
Validation Accuracy:0.9311594243930734
Validation Accuracy:0.9094202952540439
Validation Accuracy:0.7905797223034112
Validation Accuracy:0.8942029048567233
Validation Accuracy:0.944202901876491
Validation Accuracy:0.9347826125829116
Validation Accuracy:0.8971014554085939
Validation Accuracy:0.8891304413909498
Validation Accuracy:0.9311594243930734
Validation Accuracy:0.931884062031041
Validation Accuracy:0.8384058067332143
Loss:1.1014528008037887
Loss:0.732292862339745
Loss:0.6451098128166433
Loss:0.5897186139119102
Loss:0.6145398957367012
Loss:0.5667471829095908
Loss:0.5078108345913129
Loss:0.5482991558907363
Loss:0.5094483769965199
Loss:0.4951072606228742
Loss:0.4496546101095543
Loss:0.4725292174049797
Loss:0.41990080728311235
Loss:0.45580268251860917
Loss:0.4411211286756903
Loss:0.4621158099887899
Loss:0.39705283254388796
Loss:0.4307161986569262
Loss:0.3963451953099762
Loss:0.42057865687143414
Loss:0.3622372081933223
Loss:0.39573983487972453
Loss:0.38503487662756736
Loss:0.41324232149043527
Loss:0.39419350984435125
Loss:0.38227594306810603
Loss:0.37766256155340405
Loss:0.37595843799917067
Loss:0.38765924514534067
Loss:0.3473872989929497
Loss:0.3875276875523291
Loss:0.37769095865465085
Loss:0.40114915949532887
Loss:0.35741922789056857
Loss:0.4200542443364771
Loss:0.3477182717853866
Loss:0.37305369721819465
Loss:0.3315723861539274
Loss:0.37497791873035163
Loss:0.3730682378481036
Loss:0.34907794652795004
Loss:0.31798317552533123
Loss:0.32751835748806163
Loss:0.35187669064912835
Loss:0.37968258789961656
Loss:0.35772984981901934
Loss:0.36978314954802227
Loss:0.32488153637391015
Loss:0.39558632829838203
Loss:0.3218020022075152
Loss:0.36332206996185096
Loss:0.30392239119297115
Loss:0.33280381231005585
Loss:0.3222554765562782
Loss:0.3438938636752481
Loss:0.3143353117193755
Loss:0.3065156885232033
Loss:0.3166939422147865
Loss:0.30218796435250633
Loss:0.35993877672447117
Validation Loss:0.25468851966054545
Validation Loss:0.24406195227967817
Validation Loss:0.2139551455721907
Validation Loss:0.266347498496306
Validation Loss:0.2023113586777902
Validation Loss:0.28853464811665774
Validation Loss:0.27031705782207177
Validation Loss:0.2005858225596097
Validation Loss:0.22849458234850317
Validation Loss:0.2279153634875041
Validation Loss:0.187233255457376
Validation Loss:0.18716473502876319
Validation Loss:0.24969323654659092
Validation Loss:0.1796937331698997
Validation Loss:0.18226804095573482
Validation Loss:0.20196816237686385
Validation Loss:0.2729522828012705
Validation Loss:0.19317869756512507
Validation Loss:0.18730598091876702
Validation Loss:0.24068814018012388
Validation Loss:0.5081234297350697
Validation Loss:0.21431302274172398
Validation Loss:0.2011968285052875
Validation Loss:0.1846057106184004
Validation Loss:0.341625575421621
Validation Loss:0.4609618819440189
Validation Loss:0.22466016690368237
Validation Loss:0.3730138139799237
Validation Loss:0.49708742672658485
Validation Loss:0.2052581736706602
Validation Loss:0.2926422023902769
Validation Loss:0.18552656214603264
Validation Loss:0.19642479787074515
Validation Loss:0.19435734150718656
Validation Loss:0.1929755175724099
Validation Loss:0.18947576298175947
Validation Loss:0.19519814072966413
Validation Loss:0.1953099797145747
Validation Loss:0.2180409226262861
Validation Loss:0.5576648185758487
Validation Loss:0.6374475241679213
Validation Loss:0.5988237229378327
Validation Loss:0.6752045910157587
Validation Loss:0.20948410369253354
Validation Loss:0.7183361845495908
Validation Loss:0.21834254786169724
Validation Loss:0.32682657065679843
Validation Loss:0.5762137471819702
Validation Loss:0.24368360881572185
Validation Loss:0.2751845920663428
Validation Loss:0.27876702188919095
Validation Loss:0.6068749432654484
Validation Loss:0.32372579545430513
Validation Loss:0.1958708696234364
Validation Loss:0.219616200906508
Validation Loss:0.32150275561877567
Validation Loss:0.3387527002993485
Validation Loss:0.23114645620808005
Validation Loss:0.23041597061345112
Validation Loss:0.5087748635560274
Confusion MatrixTN:961 FP:211 FN:12 TP:196
             precision    recall  f1-score   support

  No Litter       0.99      0.82      0.90      1172
     Litter       0.48      0.94      0.64       208

avg / total       0.91      0.84      0.86      1380

DATE:2018-10-09 13:55
